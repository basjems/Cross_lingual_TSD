{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Predicting and evaluating models for Toxic Spans Detection\n",
        "\n",
        "This notebook contains the code for predicting toxic spans and evaluating the predictions. It is designed for use in Google colab and requires you to give access to Google Drive. Run the notebook fine_tune_TSD first to fine-tune models and save them to Google Drive."
      ],
      "metadata": {
        "id": "8FBqglG9kMHb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUuCjQhQOFEy",
        "outputId": "c604bfb8-5283-42af-9b17-622e05be9165"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.28.1 in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (3.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (0.0.53)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2022.10.31)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "#install modules\n",
        "!pip install transformers==4.28.1\n",
        "!pip install sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "tRa3ajAPOKzY"
      },
      "outputs": [],
      "source": [
        "#import modules\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, BatchEncoding, Trainer\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import ast\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import json\n",
        "from statistics import mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GJx7x3Bb3Bn",
        "outputId": "92a2dc6b-cebf-4157-8953-c92cc3105404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#connect drive: a pop-up will allow you to give access to your drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import git repository to collect the test data\n",
        "!git clone https://github.com/tommasoc80/DALC\n",
        "!git clone https://github.com/basjems/Cross_lingual_TSD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9djWc8PkWev",
        "outputId": "8ebc1f79-85c7-4d24-e06b-772307c95e81"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DALC'...\n",
            "remote: Enumerating objects: 210, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 210 (delta 12), reused 28 (delta 4), pack-reused 164\u001b[K\n",
            "Receiving objects: 100% (210/210), 3.53 MiB | 10.71 MiB/s, done.\n",
            "Resolving deltas: 100% (92/92), done.\n",
            "fatal: destination path 'Cross_lingual_TSD' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREPROCESS DATA\n",
        "\n",
        "Run the cells below to define functions for data preprocessing."
      ],
      "metadata": {
        "id": "sHblDqkIkb3X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "MVBfVMsXOQ_F"
      },
      "outputs": [],
      "source": [
        "class TSDdataset(torch.utils.data.Dataset):\n",
        "    #inspired by https://huggingface.co/transformers/v4.1.1/custom_datasets.html\n",
        "    \"\"\"Aligns tokens with annotation labels (I/O), given a BatchEncoding (a tokenized text) and a list of character offsets.\n",
        "    Param BatchEncoding tokenized: a tokenized sentence that has been tokenized by a FastTokenizer.\n",
        "    Param annotations: a list or string that indicates the character indices that are toxic spans. \"\"\"\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "def align_tokens_and_annotation_labels(tokenized: BatchEncoding, annotations: str, max_len, pad_token):\n",
        "  \"\"\"Preprocesses a dict of .csv files into a dictionary TSDdataset objects.\n",
        "    Param files: a dict holding paths to .csv files to be preprocessed. Keys should be 'train' 'dev' and/or 'test', values should be paths to respective data file.\n",
        "    tokenizer: an AutoTokenizer with which we want to preprocess the data.\"\"\"\n",
        "    #create aligned_labels as a list of 0's, length equals the number of tokens\n",
        "  aligned_labels = [0] * len([ids for ids in tokenized.ids if id != 0])\n",
        "    #convert annotation from str to list\n",
        "  spanlist = ast.literal_eval(annotations)\n",
        "\n",
        "    #iterate over indices in the span list\n",
        "  for char_ix in spanlist:\n",
        "        #Find the corresponding token index\n",
        "      token_ix = tokenized.char_to_token(char_ix)\n",
        "        #Change the value in aligned_labels to 1 (I)\n",
        "      if token_ix is not None: # White spaces have no token and will return None\n",
        "        aligned_labels[token_ix] = 1\n",
        "\n",
        "  n_pad_tokens = max_len-len(aligned_labels)\n",
        "  aligned_labels += [pad_token]*n_pad_tokens\n",
        "\n",
        "  return aligned_labels\n",
        "\n",
        "def preprocess(file_dict, tokenizer, pad_token=-100, max_len=512):\n",
        "\n",
        "  TSD_datasetdict = {}\n",
        "\n",
        "  for data_type, file in file_dict.items():\n",
        "\n",
        "    df = pd.read_csv(file)\n",
        "    spans = list(df['spans'])\n",
        "    tweets = list(df['text'])\n",
        "    texts = []\n",
        "\n",
        "    for text in tweets:\n",
        "      text = text.replace('#', '')\n",
        "      text = text.replace('URL', '')\n",
        "      texts.append(text)\n",
        "\n",
        "    encodings = tokenizer(texts, truncation = True, max_length = max_len, padding = 'max_length')\n",
        "\n",
        "    labels = [align_tokens_and_annotation_labels(tokenized, annotation, max_len, pad_token) for tokenized, annotation in zip(tokenizer(texts).encodings, spans)]\n",
        "    # TSD_dataset =\n",
        "    # batch = data_collator(TSD_dataset)\n",
        "    TSD_datasetdict[data_type] = TSDdataset(encodings, labels)\n",
        "\n",
        "\n",
        "  return TSD_datasetdict\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Helper functions\n",
        "Run the cells below to define the functions needed for for evaluating, converting predictions to spans, and converting spans to words."
      ],
      "metadata": {
        "id": "TaEVtsW6pi5R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "ANeK_sDK3qnJ"
      },
      "outputs": [],
      "source": [
        "def divide_list_into_consecutive_sequences(char_list):\n",
        "  \"\"\"divides a list of ints into sublists of consecutive sequences.\n",
        "  Param char_list: the list of ints.\n",
        "  Returns: a list of lists of all consecutive sequences in the char_list. \"\"\"\n",
        "  if char_list == []:\n",
        "    return []\n",
        "  new_list = [[char_list[0]]]\n",
        "  for i in char_list[1:]:\n",
        "    new_list[-1].append(i) if new_list[-1][-1] == i-1 else new_list.append([i])\n",
        "  return new_list\n",
        "\n",
        "def spans_to_words(spans, text):\n",
        "  \"\"\"Converts lists of character indices (spans) to text.\n",
        "  Param spans: a list of lists that hold a span for each tweet.\n",
        "  param text: a list of tweet texts.\n",
        "  Returns: a list of lists that holds the words in the tweet that correspond to the span.\"\"\"\n",
        "  all_words = []\n",
        "  for span_list, tweet in zip(spans, text):\n",
        "    words = []\n",
        "    if type(span_list) == str:\n",
        "      span_list = ast.literal_eval(span_list)\n",
        "\n",
        "    span_list = sorted(span_list)\n",
        "    if len(span_list) > 0:\n",
        "      span_list_per_word = divide_list_into_consecutive_sequences(span_list)\n",
        "      for span in span_list_per_word:\n",
        "        word = ''.join([tweet[ix] for ix in span])\n",
        "        words.append(word)\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "    all_words.append(words)\n",
        "\n",
        "  return all_words\n",
        "\n",
        "\n",
        "def convert_token_predictions_to_spans(binary_predictions, test_dataset, text_list, pad_token=-100):\n",
        "  \"\"\"converts predictions on a token level to predictions on a span level.\n",
        "  Param binary_predictions: a list of lists of binary token predictions.\n",
        "  Param test_dataset: a TSDdataset that holds the tokenized data.\n",
        "  Param text_list: a list of texts in the data.\n",
        "  Param pad_token: the pad_token (as assigned in the preprocess function)\n",
        "  Returns: a list of lists of predicted toxic spans.\n",
        "  \"\"\"\n",
        "  all_spans = []\n",
        "  for tweet_idx, predictions in enumerate(binary_predictions):\n",
        "    cur_tweet = text_list[tweet_idx]\n",
        "    tweet_spans = []\n",
        "    toxic_words = []\n",
        "    for token_idx, pred_token in enumerate(predictions):\n",
        "      if test_datasetdict.labels[tweet_idx][token_idx] != pad_token:\n",
        "        if pred_token == 1:\n",
        "          cur_tweet = text_list[tweet_idx]\n",
        "\n",
        "          token_span = test_datasetdict.encodings.token_to_chars(tweet_idx, token_idx)\n",
        "          tweet_spans += [idx for idx in range(token_span.start, token_span.end) if cur_tweet[idx] != ' ']\n",
        "\n",
        "      else:\n",
        "        break\n",
        "\n",
        "    all_spans.append(tweet_spans)\n",
        "\n",
        "  return all_spans\n",
        "\n",
        "\n",
        "def calculate_evaluation_metrics(gold, pred):\n",
        "    \"\"\"Calculates averaged f1, precision and recall for TSD, via the metric defined by Pavlopoulos et al's \"SemEval-2021 Task 5: Toxic Spans Detection\" (2021)\n",
        "    Param gold: the gold labels (list of lists of character indices)\n",
        "    Param pred: system predictions (list of lists of character indices)\n",
        "    Returns: a dictionary holding precision, recall and f1\"\"\"\n",
        "  all_precision = []\n",
        "  all_recall = []\n",
        "  all_f1 = []\n",
        "\n",
        "  for tweet_gold, tweet_pred in zip(gold,pred):\n",
        "\n",
        "\n",
        "    if type(tweet_gold) == str:\n",
        "      tweet_gold = ast.literal_eval(tweet_gold)\n",
        "    if type(tweet_pred) == str:\n",
        "      tweet_pred = ast.literal_eval(tweet_pred)\n",
        "\n",
        "\n",
        "    if tweet_gold == [] and tweet_pred == []:\n",
        "      precision, recall, f1 = 1,1,1\n",
        "    elif tweet_gold == [] or tweet_pred == []:\n",
        "      precision, recall, f1 = 0,0,0\n",
        "    else:\n",
        "      tweet_pred, tweet_gold = set(tweet_pred), set(tweet_gold)\n",
        "\n",
        "      precision = len((tweet_gold).intersection(tweet_pred))/len(tweet_pred)\n",
        "      recall = len((tweet_gold).intersection(tweet_pred))/len(tweet_gold)\n",
        "      try:\n",
        "        f1 = 2*(precision*recall)/(precision+recall)\n",
        "      except ZeroDivisionError:\n",
        "        f1= 0\n",
        "\n",
        "    if f1 < recall and f1 < precision:\n",
        "      print(f1, recall, precision)\n",
        "\n",
        "    all_precision.append(precision)\n",
        "    all_recall.append(recall)\n",
        "    all_f1.append(f1)\n",
        "\n",
        "  return {\n",
        "          'precision': mean(all_precision),\n",
        "          'recall': mean(all_recall),\n",
        "          'f1': mean(all_f1),\n",
        "          }\n",
        "\n",
        "def predict_TSD(model_names, model_folder, gold_file, find_best_checkpoint = True, manual_checkpoint = None):\n",
        "\n",
        "  df = pd.read_csv(gold_file)\n",
        "  texts = df['text']\n",
        "  gold_spans = [ast.literal_eval(span) for span in list(df['spans'])]\n",
        "  df[\"gold words\"] = spans_to_words(gold_spans, df['text'])\n",
        "\n",
        "  for chkpoint in model_names:\n",
        "\n",
        "    print(f'model: {chkpoint}')\n",
        "\n",
        "    #preprocess data\n",
        "    print('downloading tokenizer...')\n",
        "    tokenizer = AutoTokenizer.from_pretrained(chkpoint)\n",
        "    print('processing data...')\n",
        "    datasetdict = preprocess({'test':gold_file}, tokenizer)\n",
        "\n",
        "    destination_folder = f\"{model_folder}/{chkpoint.replace('/', '_')}_trained_for_TSD\"\n",
        "    if find_best_checkpoint:\n",
        "\n",
        "    #find latest model checkpoint\n",
        "      checkpoint_numbers = [int(file.split('-')[1]) for file in os.listdir(destination_folder) if file.startswith('checkpoint')]\n",
        "      latest_checkpoint = max(checkpoint_numbers)\n",
        "      checkpoint_size = min(checkpoint_numbers)\n",
        "\n",
        "      with open(f\"{destination_folder}/checkpoint-{latest_checkpoint}/trainer_state.json\", 'r') as infile:\n",
        "        trainer_state = json.load(infile)\n",
        "      all_epoch_f1_scores = [float(epoch['eval_f1']) for epoch in trainer_state['log_history'] if 'eval_f1' in epoch]\n",
        "      best_epoch = all_epoch_f1_scores.index(max(all_epoch_f1_scores))+1\n",
        "      best_model = f\"{destination_folder}/checkpoint-{checkpoint_size*best_epoch}\"\n",
        "      print(f'best epoch: {best_epoch}')\n",
        "\n",
        "    else:\n",
        "      best_model = f\"{destination_folder}/checkpoint-{manual_checkpoint}\"\n",
        "\n",
        "    print(f'loading best model...')\n",
        "    trained_model = AutoModelForTokenClassification.from_pretrained(best_model, num_labels = 2)\n",
        "\n",
        "    #predict data\n",
        "    test_trainer = Trainer(trained_model)\n",
        "    print(\"predicting...\")\n",
        "    raw_pred, _, _ = test_trainer.predict(datasetdict['test']) #trained model was trainer before\n",
        "    binary_predictions = y_pred = np.argmax(raw_pred, axis=-1)\n",
        "    predicted_spans = convert_token_predictions_to_spans(binary_predictions, datasetdict['test'], texts)\n",
        "\n",
        "    #add data to the df\n",
        "    df[f\"predictions {chkpoint}\"] = predicted_spans\n",
        "    # df[f\"words {chkpoint}\"] = spans_to_words(predicted_spans, df['text'])\n",
        "    print(\"predictions finished\\n\")\n",
        "\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making predictions\n",
        "Fill in the model checkpoints for which you want to make predictions below and run the cell."
      ],
      "metadata": {
        "id": "u6SC14x9pqAN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "XNfjQb75plTx",
        "outputId": "1354e908-5964-484d-9b59-787111ad2180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model: facebook/xlm-v-base\n",
            "downloading tokenizer...\n",
            "processing data...\n",
            "best epoch: 3\n",
            "loading best model...\n",
            "predicting...\n",
            "dict_items([('test', <__main__.TSDdataset object at 0x7fe3696b3820>)])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions finished\n",
            "\n",
            "model: xlm-roberta-base\n",
            "downloading tokenizer...\n",
            "processing data...\n",
            "best epoch: 4\n",
            "loading best model...\n",
            "predicting...\n",
            "dict_items([('test', <__main__.TSDdataset object at 0x7fe36c308cd0>)])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions finished\n",
            "\n",
            "model: bert-base-multilingual-cased\n",
            "downloading tokenizer...\n",
            "processing data...\n",
            "best epoch: 3\n",
            "loading best model...\n",
            "predicting...\n",
            "dict_items([('test', <__main__.TSDdataset object at 0x7fe36c321fc0>)])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions finished\n",
            "\n",
            "model: distilbert-base-multilingual-cased\n",
            "downloading tokenizer...\n",
            "processing data...\n",
            "best epoch: 4\n",
            "loading best model...\n",
            "predicting...\n",
            "dict_items([('test', <__main__.TSDdataset object at 0x7fe3696b3820>)])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions finished\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_checkpoints =  ['facebook/xlm-v-base', 'xlm-roberta-base', 'bert-base-multilingual-cased', 'distilbert-base-multilingual-cased']\n",
        "model_folder = f\"/content/drive/MyDrive/models_trained_for_TSD\"\n",
        "gold_file = \"/content/Cross_lingual_TSD/data/annotated_test_set_hashtags_removed.csv\"\n",
        "\n",
        "TSD_df = predict_TSD(model_checkpoints, model_folder, gold_file)# overwrite = True, find_best_checkpoint=False, manual_checkpoint = 28)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predictions are finished.\n",
        "TSD_df now holds predictions for all language models.\n",
        "The next function calculates the evaluation metrics for each model and prints them."
      ],
      "metadata": {
        "id": "76NYaI9FkKgO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59gy3YhcTw4d",
        "outputId": "986fa307-5dee-4823-bba5-50bb454e6b26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint: facebook/xlm-v-base\n",
            "precision : 0.7127841383348249\n",
            "recall : 0.6917749659067799\n",
            "f1 : 0.6583874396831174\n",
            "\n",
            "checkpoint: xlm-roberta-base\n",
            "precision : 0.6966266610784485\n",
            "recall : 0.6261557998625287\n",
            "f1 : 0.6202935622472588\n",
            "\n",
            "checkpoint: bert-base-multilingual-cased\n",
            "precision : 0.47067908584936446\n",
            "recall : 0.414969253774076\n",
            "f1 : 0.40377840431918266\n",
            "\n",
            "checkpoint: distilbert-base-multilingual-cased\n",
            "precision : 0.43779374399438864\n",
            "recall : 0.3863564265044897\n",
            "f1 : 0.37917760044139975\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def print_eval_metrics(model_checkpoints, df):\n",
        "  \"\"\"Print evaluation metrics using the df that is the output of predict_TSD.\n",
        "  Param model_ceckpoints\"\"\"\n",
        "  gold = df['spans']\n",
        "  model_f1_dict = {}\n",
        "  for chkpoint in model_checkpoints:\n",
        "    print(f'checkpoint: {chkpoint}')\n",
        "    pred = df[f'predictions {chkpoint}']\n",
        "    eval = calculate_evaluation_metrics(gold, pred)\n",
        "    for k, v in eval.items():\n",
        "      if k != 'f1_dict':\n",
        "        print(f'{k} : {v}')\n",
        "    model_f1_dict[chkpoint] = eval\n",
        "    print()\n",
        "\n",
        "  return model_f1_dict\n",
        "\n",
        "eval = print_eval_metrics(model_checkpoints, TSD_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lexicon system\n",
        "\n",
        "Run the following cell to run a lexicon look-up system and add the results to the TSD_df."
      ],
      "metadata": {
        "id": "WjoG6xGPlgP-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "KC9PkLucaOAn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938,
          "referenced_widgets": [
            "895e93a4e6814753a71213babbaa2160",
            "4d30acc5c35f4e5cae4e71f84a476588",
            "9ab8b2ab38d34fa08964180661751171",
            "08f6d737c33b4ecb82528865c595668b",
            "360e3aa7ccc94bba9f980e2b9ab66f23",
            "9559cf20c6fc4f238611e165b4c50db0",
            "f2a58912ae7a469cb55f308f077b48a2",
            "0a311170ae48402694548d5e91f6c546",
            "2bb0c01ec24f4c0ba1d37d384b5fe308",
            "6a97e4737cc04ba2acad3e6a96e47e7f",
            "d5d64c262fc84101867bd3b1c7644516",
            "a6a9897a64754f80b47f636e8e1321fa",
            "f89b413d35014b4eb6a22a19cf24da66",
            "dc76570d9e4d46549ac548479c3d4df7",
            "67fe74eb43c84bafb9c0054bc3c31f72",
            "185b20311c6842c7badcf0dab5248ed0",
            "179f29ec3a47432c999278b1bee9e63a",
            "d7eaeddd77584801a818a87c5fc1c96e",
            "2b3d9565310a4a25b806f72b648df31b",
            "8e34859a535446a08f734c47d89939bd",
            "4331b550a72542399eb6e2807f6c039e",
            "e092fd409d244d31a53553b9581bcf2c"
          ]
        },
        "outputId": "a5b849bc-4a69-4bb5-b442-6e4eea835e59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stanza in /usr/local/lib/python3.10/dist-packages (1.5.0)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from stanza) (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.22.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from stanza) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->stanza) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->stanza) (16.0.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "895e93a4e6814753a71213babbaa2160"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloading default packages for language: nl (Dutch) ...\n",
            "INFO:stanza:File exists: /root/stanza_resources/nl/default.zip\n",
            "INFO:stanza:Finished downloading models and saved to /root/stanza_resources.\n",
            "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6a9897a64754f80b47f636e8e1321fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Loading these models for language: nl (Dutch):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | alpino  |\n",
            "| pos       | alpino  |\n",
            "| lemma     | alpino  |\n",
            "| depparse  | alpino  |\n",
            "| ner       | conll02 |\n",
            "=======================\n",
            "\n",
            "INFO:stanza:Using device: cuda\n",
            "INFO:stanza:Loading: tokenize\n",
            "INFO:stanza:Loading: pos\n",
            "INFO:stanza:Loading: lemma\n",
            "INFO:stanza:Loading: depparse\n",
            "INFO:stanza:Loading: ner\n",
            "INFO:stanza:Done loading processors!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "847\n"
          ]
        }
      ],
      "source": [
        "#install stanza and prepare nlp pipeline\n",
        "!pip install stanza\n",
        "import stanza\n",
        "stanza.download('nl')\n",
        "nlp=stanza.Pipeline(lang='nl')\n",
        "\n",
        "def lexicon_baseline(lexicon_file, tweet_file):\n",
        "  \"\"\"A lexicon baseline system that predicts toxic spans in tweets.\n",
        "  Param lexicon_file: the path to the lexicon file.\n",
        "  Param tweet_file: the path to the file that holds the to be predicted twetes.\n",
        "  returns: a list of lists that hold the predicted spans for each tweet. \"\"\"\n",
        "\n",
        "  tweets = list(pd.read_csv(tweet_file)['text'])\n",
        "  nl_words = list(pd.read_csv(lexicon_file, sep='\\t')['lemma'])\n",
        "  lexicon_spans = []\n",
        "  for tweet in tweets:\n",
        "    doc = nlp(tweet)\n",
        "    spans =[]\n",
        "    for sent in doc.sentences:\n",
        "      for word in sent.words:\n",
        "        for scheldwoord in nl_words:\n",
        "\n",
        "          if word.lemma == scheldwoord:\n",
        "            start = int(word.start_char)\n",
        "            end = int(word.end_char)\n",
        "            if word.text.startswith('#'):\n",
        "              start += 1\n",
        "            for i in range(start, end):\n",
        "              spans.append(i)\n",
        "\n",
        "    lexicon_spans.append(spans)\n",
        "\n",
        "  return lexicon_spans\n",
        "\n",
        "lexicon_spans = lexicon_baseline('/content/DALC/GROF_LEX/groflex.tsv',gold_file)\n",
        "TSD_df['predictions lexicon'] = lexicon_spans\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voting ensembles\n",
        "\n",
        "Run the following cell to create a majority voting ensemble. By changing the 'df' and\n",
        "'n' parameter, we can change the ensemble."
      ],
      "metadata": {
        "id": "ziZrak5xlxa7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "KRbjM4uX563J"
      },
      "outputs": [],
      "source": [
        "def ensemble(df, n=None):\n",
        "  \"\"\"Creates an ensemble given a df with predictions of multiple systems.\n",
        "  Param df: a pandas dataframe that only contains columns with predictions we want to include in the ensemble.\n",
        "  param n: the number of systems that should have predicted a character index to make it into the vote. Defaults to the number of systems / 2.\n",
        "  Returns: a list of ensemble voting predictions.\n",
        "  \"\"\"\n",
        "  #set n to the number of systems / 2, or /2+1 if the number of systems is uneven\n",
        "  if n == None:\n",
        "    n_systems = len(df.columns)\n",
        "    n = int(n_systems/2)\n",
        "    if n_systems%2 == 1:\n",
        "      n+=1\n",
        "\n",
        "  ensemble = []\n",
        "  #iterate over the df, add spans to one list\n",
        "  for i, row in df.iterrows():\n",
        "    spans = []\n",
        "    result = []\n",
        "    for pred in row:\n",
        "      spans += pred\n",
        "\n",
        "    #if an index occurs in the spans list at least n times, add it to the result\n",
        "    for idx in set(spans):\n",
        "      if spans.count(idx) >= n:\n",
        "        result.append(idx)\n",
        "\n",
        "    ensemble.append(result)\n",
        "\n",
        "  return ensemble\n",
        "\n",
        "TSD_df['predictions best ensemble'] = ensemble(TSD_df[['predictions facebook/xlm-v-base', 'predictions xlm-roberta-base', 'predictions lexicon']])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save to file\n",
        "enter a desired file path to save the predictions to."
      ],
      "metadata": {
        "id": "E7WcuEQOoPqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_file = \"/content/[YOUR_FILE_HERE].csv\"\n",
        "TSD_df.to_csv(predictions_file)"
      ],
      "metadata": {
        "id": "dYv02YnZoQum"
      },
      "execution_count": 80,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "895e93a4e6814753a71213babbaa2160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d30acc5c35f4e5cae4e71f84a476588",
              "IPY_MODEL_9ab8b2ab38d34fa08964180661751171",
              "IPY_MODEL_08f6d737c33b4ecb82528865c595668b"
            ],
            "layout": "IPY_MODEL_360e3aa7ccc94bba9f980e2b9ab66f23"
          }
        },
        "4d30acc5c35f4e5cae4e71f84a476588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9559cf20c6fc4f238611e165b4c50db0",
            "placeholder": "​",
            "style": "IPY_MODEL_f2a58912ae7a469cb55f308f077b48a2",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: "
          }
        },
        "9ab8b2ab38d34fa08964180661751171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a311170ae48402694548d5e91f6c546",
            "max": 30101,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2bb0c01ec24f4c0ba1d37d384b5fe308",
            "value": 30101
          }
        },
        "08f6d737c33b4ecb82528865c595668b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a97e4737cc04ba2acad3e6a96e47e7f",
            "placeholder": "​",
            "style": "IPY_MODEL_d5d64c262fc84101867bd3b1c7644516",
            "value": " 216k/? [00:00&lt;00:00, 14.3MB/s]"
          }
        },
        "360e3aa7ccc94bba9f980e2b9ab66f23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9559cf20c6fc4f238611e165b4c50db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2a58912ae7a469cb55f308f077b48a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a311170ae48402694548d5e91f6c546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bb0c01ec24f4c0ba1d37d384b5fe308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a97e4737cc04ba2acad3e6a96e47e7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5d64c262fc84101867bd3b1c7644516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6a9897a64754f80b47f636e8e1321fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f89b413d35014b4eb6a22a19cf24da66",
              "IPY_MODEL_dc76570d9e4d46549ac548479c3d4df7",
              "IPY_MODEL_67fe74eb43c84bafb9c0054bc3c31f72"
            ],
            "layout": "IPY_MODEL_185b20311c6842c7badcf0dab5248ed0"
          }
        },
        "f89b413d35014b4eb6a22a19cf24da66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_179f29ec3a47432c999278b1bee9e63a",
            "placeholder": "​",
            "style": "IPY_MODEL_d7eaeddd77584801a818a87c5fc1c96e",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: "
          }
        },
        "dc76570d9e4d46549ac548479c3d4df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b3d9565310a4a25b806f72b648df31b",
            "max": 30101,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e34859a535446a08f734c47d89939bd",
            "value": 30101
          }
        },
        "67fe74eb43c84bafb9c0054bc3c31f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4331b550a72542399eb6e2807f6c039e",
            "placeholder": "​",
            "style": "IPY_MODEL_e092fd409d244d31a53553b9581bcf2c",
            "value": " 216k/? [00:00&lt;00:00, 13.8MB/s]"
          }
        },
        "185b20311c6842c7badcf0dab5248ed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "179f29ec3a47432c999278b1bee9e63a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7eaeddd77584801a818a87c5fc1c96e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b3d9565310a4a25b806f72b648df31b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e34859a535446a08f734c47d89939bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4331b550a72542399eb6e2807f6c039e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e092fd409d244d31a53553b9581bcf2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}